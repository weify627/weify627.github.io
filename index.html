<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />

<title>Fangyin Wei</title>

  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css">
  <link href='http://fonts.googleapis.com/css?family=Lato:400,700' rel='stylesheet' type='text/css'>
  <link href="css/style.css" rel="stylesheet" type="text/css" />
<script type="text/javascript" src="js/hidebib.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-125963525-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-125963525-1');
</script>

</head>

<body>
  <div class="container">
    <table width="900" border="0" align="center" cellpadding="20">
      <table width="90%" align="center" border="0" cellpadding="10">
        <tr>
          <td width="70%" align="center" valign="top">
            <p align="center">&nbsp;</p>
	    <h2>Fangyin Wei</h2>
            <!--p align="center"><font size="6px">Fangyin Wei</font><br-->
            <!--<p align="center">fwei@princeton.edu</p>-->
             <p align="center">fangyinw (at) nvidia (dot) com</p>

             <p align="justify">
             I am a research scientist in the <a href="https://research.nvidia.com/labs/dir/">Deep Imagination Research Group</a> at NVIDIA.
			My research lies at the intersection of computer vision, computer graphics, and machine learning. I am currently interested in combining generative AI and physical simulation. Previously, I was more focused on 3D modeling, synthesis, and editing through the lens of machine learning. <!--with emphasis on-->
            </p>

             <p align="justify">
             I received my Ph.D. at <a href="https://www.princeton.edu/">Princeton University</a>,
		    where I was co-advised by <a href="https://www.cs.princeton.edu/~smr/">Szymon Rusinkiewicz</a> and <a href="https://www.cs.princeton.edu/~funk/">Thomas Funkhouser</a>.
			Prior to joining Princeton, I got my Bachelor's in Computer Science and Economy from <a href="http://www.pku.edu.cn/">Peking University</a>.
			 I was a research intern at Meta Reality Labs, Uber ATG R&#38;D, Google Research, Microsoft Research Asia, and
             Stanford University.
            </p>
             <!--<a href="http://research.microsoft.com/en-us/labs/asia/">Microsoft Research Asia</a>,
             Stanford University (advised by <a href="http://graphics.stanford.edu/~guibas">Prof. Leonidas Guibas</a>),
             and <a href="https://www.sensetime.com/?lang=en-us">Sensetime Group Limited</a>Intelligence Science and Technology.-->
            <p style="color:#FF0000" align="justify">
            </p>
			<a href="https://scholar.google.com/citations?user=w9rFBkEAAAAJ&hl=en&oi=ao" target="_blank"><img src="icons/google_scholar.png" height="16"></a> /
            <a href="https://www.linkedin.com/in/fangyin-wei-4b5b2aa6/" target="_blank" ><img src="icons/linkedin.png" height="16"></a> /
            <a href="https://x.com/FangyinWei" target="_blank" ><img src="icons/x.jpg" height="16"></a>
			 <!--/<a href="cv.pdf"><img src="icons/cv.png" height="16"></a> /
                <a href="" target="_blank" ><img src="icons/github_alt.png" height="16"></a>-->
            </p>
          </td>
          <td width="30%" align="right"><div class="instructorphoto"><img src="./fig/myphoto.jpg" id="fangyin"></div></td>
        </tr>
      </table>
    </table>
  </div>
  <br>
<!--
  <div class="container">
    <table width="90%" border="0" align="center" cellpadding="20">
    <h2>News</h2>
      <div class="news">
        <ul>
         <li><span> Coming soon...
        </ul>
      </div>
    </table>
  </div>
  <br>
-->
  <div class="container">
    <h2>News / Invited Talks</h2>
    <br>
    <div style="max-height: 200px; overflow-y: auto; padding-right: 15px; border: 1px solid #e0e0e0; border-radius: 5px; padding: 15px; background-color: #fafafa;">
        <ul align="left" style="margin: 0; padding-left: 20px;">
            <li> 05/2025 We will be organizing the 1st workshop on <a href="https://visionmeetphysics.github.io">Vision Meets Physics (SimVision)</a> at CVPR 2025.
            <li> 04/2024 I defended my dissertation "Learning to Edit 3D Objects and Scenes"!
            <li> 10/2023 I gave a talk at the MMLab @ Nanyang Technological University.
            <li> 10/2023 I gave a talk at the CVRP Lab @ National University of Singapore.
            <li> 07/2023 I gave a talk at the Deep Learning Seminar @ Westlake University.
            <li> 07/2023 I gave a talk at the 3D Vision Group @ Zhejiang University.
            <li> 03/2023 I gave a talk at the Immersive Computing Lab @ NYU.
            <li> 02/2023 I gave a talk at the Vision Seminar @ UC Berkeley.
            <li> 02/2023 I gave a talk at the Stanford Computational Imaging Lab.
            <li> 12/2022 I gave a talk at the AI Seminar @ UC San Diego.
            <li> 08/2022 I gave a talk at Peking University.
        </ul>
    </div>
  </div>
    <br>
  <div class="container">
    <h2> Publications </h2>

    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="25%" valign="top">
                <img src="fig/sage2026.gif" alt="SAGE" width="180" />
        <td width="75%" valign="top">
						<h4><h4><span class="h4">SAGE: Scalable Agentic 3D Scene Generation for Embodied AI
								</span></h4>
				<h5>
              <a href="https://xiahongchi.github.io/">Hongchi Xia</a>,
              <a href="https://xuan-li.github.io/">Xuan Li</a>,
              <a href="https://mli0603.github.io/">Zhaoshuo Li</a>,
              <a href="https://qianlim.github.io/">Qianli Ma</a>,
              <a href="https://cnut1648.github.io/">Jiashu Xu</a>,
              <a href="https://mingyuliu.net/">Ming-Yu Liu</a>,
              <a href="https://ycui.me/">Yin Cui</a>,
              <a href="https://tsungyilin.info/">Tsung-Yi Lin</a>,
              <a href="https://www.cs.cornell.edu/~weichiu/">Wei-Chiu Ma</a>,
              <a href="https://shenlong.web.illinois.edu/">Shenlong Wang</a>,
              <a href="https://shurans.github.io/">Shuran Song</a>,
              <strong>Fangyin Wei</strong>
        </h5>

          <em></em>CVPR, 2026 &nbsp
          <div class="paper" id="sage">
							<a href="https://arxiv.org/abs/2602.10116">paper</a> /
            <a href="https://nvlabs.github.io/sage/">webpage</a> /
            <a href="https://github.com/NVlabs/SAGE">code</a> /
            <a href="https://huggingface.co/datasets/nvidia/SAGE-10k">dataset</a> /
            <a shape="rect" href="javascript:togglebib('sage')" class="togglebib">bibtex</a>
            <pre xml:space="preserve">
              @article{xia2026sage,
                title={SAGE: Scalable Agentic 3D Scene Generation for Embodied AI},
                author={Xia, Hongchi and Li, Xuan and Li, Zhaoshuo and Ma, Qianli and Xu, Jiashu and Liu, Ming-Yu and Cui, Yin and Lin, Tsung-Yi and Ma, Wei-Chiu and Wang, Shenlong and Song, Shuran and Wei, Fangyin},
                journal={arXiv preprint arXiv:2602.10116},
                year={2026}
              }
            </pre>
          </div>
        </td>
        </td>
      </table>
    </div>
    <hr>

    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="25%" valign="top">
                <video autoplay loop muted width="180">
                    <source src="fig/cosmos-transfer2.5.mp4" type="video/mp4">
                </video>
        <td width="75%" valign="top">
						<h4><h4><span class="h4">World Simulation with Video Foundation Models for Physical AI
								</span></h4>
				<h5>
                    NVIDIA (<strong>Fangyin Wei</strong>: core contributor)
        </h5>

          <em></em>arXiv, 2025 &nbsp
          <div class="paper" id="cosmos-2.5">
							<a href="https://arxiv.org/abs/2511.00062">paper</a> / Cosmos-Predict2.5
            (<a href="https://research.nvidia.com/labs/dir/cosmos-predict2.5/">webpage</a>,
             <a href="https://github.com/nvidia-cosmos/cosmos-predict2.5">code</a>) / Cosmos-Transfer2.5
             (<a href="https://research.nvidia.com/labs/dir/cosmos-transfer2.5/">webpage</a>,
             <a href=" https://github.com/nvidia-cosmos/cosmos-transfer2.5">code</a>)
            <!--<a shape="rect" href="javascript:togglebib('cosmos-reason1')" class="togglebib">bibtex</a>-->
            <!--<pre xml:space="preserve">-->
            </pre>
          </div>
        </td>
        </td>
      </table>
    </div>
    <hr>

    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="25%" valign="top">
                <video autoplay loop muted width="180">
                    <source src="fig/partpacker.mp4" type="video/mp4">
                </video>
        <td width="75%" valign="top">
						<h4><h4><span class="h4">PartPacker: Efficient Part-level 3D Object Generation via Dual Volume Packing
								</span></h4>
				<h5>
              <a href="https://me.kiui.moe">Jiaxiang Tang</a>,
              <a href="https://jason-aplp.github.io/Ruijie-Lu/">Ruijie Lu</a>,
              <a href="https://mli0603.github.io/">Zhaoshuo Li</a>,
              <a href="https://zekunhao.com/">Zekun Hao</a>,
              <a href="https://xuan-li.github.io/">Xuan Li</a>,
			  <strong>Fangyin Wei</strong>,
              <a href="https://shurans.github.io/">Shuran Song</a>,
              <a href="http://www.cis.pku.edu.cn/info/1177/1378.htm">Gang Zeng</a>,
              <a href="https://mingyuliu.net/">Ming-Yu Liu</a>,
              <a href="https://tsungyilin.info/">Tsung-Yi Lin</a>
        </h5>

          <em></em>NeurIPS, 2025 &nbsp
          <div class="paper" id="partpacker">
							<a href="https://arxiv.org/abs/2506.09980/">paper</a> /
            <a href="https://research.nvidia.com/labs/dir/partpacker/">webpage</a> /
            <a href="https://github.com/NVlabs/PartPacker/">code</a> /
            <a href="https://huggingface.co/spaces/nvidia/PartPacker/">demo</a>
            <!--<a shape="rect" href="javascript:togglebib('cosmos-reason1')" class="togglebib">bibtex</a>-->
            <!--<pre xml:space="preserve">-->
            </pre>
          </div>
        </td>
        </td>
      </table>
    </div>
    <hr>

    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="25%" valign="top">
                <video autoplay loop muted width="180">
                    <source src="fig/cosmos-reason1.mp4" type="video/mp4">
                </video>
        <td width="75%" valign="top">
						<h4><h4><span class="h4">Cosmos-Reason1: From Physical Common Sense To Embodied Reasoning
								</span></h4>
				<h5>
                    NVIDIA (<strong>Fangyin Wei</strong>: core contributor)
        </h5>

          <em></em>arXiv, 2025 &nbsp
          <div class="paper" id="cosmos-reason1">
							<a href="https://arxiv.org/abs/2503.15558">paper</a> /
            <a href="https://research.nvidia.com/labs/dir/cosmos-reason1/">webpage</a> /
            <a href="https://github.com/nvidia-cosmos/cosmos-reason1">code</a> /
            <a href="https://youtu.be/Eu25r-yisPc?si=YQa-XzViC7txrre6">video</a>
            <!--<a shape="rect" href="javascript:togglebib('cosmos-reason1')" class="togglebib">bibtex</a>-->
            <!--<pre xml:space="preserve">-->
            </pre>
          </div>
        </td>
        </td>
      </table>
    </div>
    <hr>

    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="25%" valign="top"><img src="fig/cvpr2025-artiscene.jpg" alt="artiscene" width="180"  style="border-style: none">
        <td width="75%" valign="top">
						<h4><h4><span class="h4">ArtiScene: Language-Driven Artistic 3D Scene Generation Through Image Intermediary
								</span></h4>
				<h5>
              <a href="https://www.cs.cornell.edu/~zeqigu/">Zeqi Gu</a>,
              <a href="https://ycui.me/">Yin Cui</a>,
              <a href="https://mli0603.github.io/">Max Li</a>,
			  <strong>Fangyin Wei</strong>,
              <a href="https://gyhandy.github.io/">Yunhao Ge</a>,
              <a href="https://www.gujinwei.org/">Jinwei Gu</a>,
              <a href="https://mingyuliu.net/">Ming-Yu Liu</a>,
              <a href="https://abedavis.com/">Abe Davis</a>,
              <a href="https://research.nvidia.com/person/yifan-ding">Yifan Ding</a>
        </h5>

          <em></em>CVPR, 2025 &nbsp
          <div class="paper" id="artiscene">
							<a href="">paper (coming)</a>
            <!--<a href="">webpage</a> /-->
            <!--<a href="">code</a> /-->
            <!--<a shape="rect" href="javascript:togglebib('cosmos-reason1')" class="togglebib">bibtex</a>-->
            <!--<pre xml:space="preserve">-->
            <!--</pre>-->
          </div>
        </td>
        </td>
      </table>
    </div>
    <hr>



    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="25%" valign="top">
                <video autoplay loop muted width="180">
                    <source src="fig/cosmos-predict1.mp4" type="video/mp4">
                </video>
        <td width="75%" valign="top">
						<h4><h4><span class="h4">Cosmos World Foundation Model Platform for Physical AI
								</span></h4>
				<h5>
                    NVIDIA (<strong>Fangyin Wei</strong>: core contributor)
        </h5>

          <em></em>arXiv, 2025 &nbsp
          <div class="paper" id="cosmos-predict1">
							<a href="https://arxiv.org/abs/2501.03575">paper</a> /
            <a href="https://www.nvidia.com/en-us/ai/cosmos/">webpage</a> /
            <a href="https://github.com/NVIDIA/Cosmos">code</a> /
            <a href="https://build.nvidia.com/explore/discover"> demo API</a>
            <!--<a shape="rect" href="javascript:togglebib('cosmos-predict1')" class="togglebib">bibtex</a>-->
            <!--<pre xml:space="preserve">-->
            <!--</pre>-->
          </div>
        </td>
        </td>
      </table>
    </div>
    <hr>


    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="25%" valign="top">
            <video autoplay loop muted width="180">
                <source src="fig/edify-3d.mp4" type="video/mp4">
            </video>
        <td width="75%" valign="top">
						<h4><h4><span class="h4">Edify 3D: Scalable High-Quality 3D Asset Generation
								</span></h4>
				<h5>
                    NVIDIA (<strong>Fangyin Wei</strong>: core contributor)
        </h5>

          <em></em>arXiv, 2024 &nbsp
          <div class="paper" id="edify3d">
							<a href="https://arxiv.org/abs/2411.07135">paper</a> /
            <a href="https://research.nvidia.com/labs/dir/edify-3d">webpage</a> /
            <a href="https://build.nvidia.com/shutterstock/edify-3d">demo API</a> /
            <a href="https://www.youtube.com/watch?v=ROqB8xhKZ6U">video</a> /
            <a shape="rect" href="javascript:togglebib('edify3d')" class="togglebib">bibtex</a>
            <pre xml:space="preserve">
@article{nvidia2024edify3d,
  title={Edify 3D: Scalable High-Quality 3D Asset Generation},
  author={NVIDIA and Bala, Maciej and Cui, Yin and Ding, Yifan and Ge, Yunhao and Hao, Zekun and Hasselgren, Jon and Huffman, Jacob and Jin, Jingyi and Lewis, J.P. and Li, Zhaoshuo and Lin, Chen-Hsuan and Lin, Yen-Chen and Lin, Tsung-Yi and Liu, Ming-Yu and Luo, Alice and Ma, Qianli and Munkberg, Jacob and Shi, Stella and Wei, Fangyin and Xiang, Donglai and Xu, Jiashu and Zeng, Xiaohui and Zhang, Qinsheng},
  journal={arXiv preprint arXiv:2411.07135},
  year={2024}
}
            </pre>
          </div>
        </td>
        </td>
      </table>
    </div>
    <hr>


    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="25%" valign="top"><img src="fig/edify-image.gif" alt="" width="180"  style="border-style: none">
        <td width="75%" valign="top">
						<h4><h4><span class="h4">Edify Image: High-Quality Image Generation with Pixel Space Laplacian Diffusion Models
								</span></h4>
				<h5>
                    NVIDIA (<strong>Fangyin Wei</strong>: contributor)
        </h5>

          <em></em>arXiv, 2024 &nbsp
          <div class="paper" id="edifyimage">
			<a href="https://arxiv.org/abs/2411.07126">paper</a> /
            <a href="https://research.nvidia.com/labs/dir/edify-image">webpage</a> /
            <a href="https://build.nvidia.com/gettyimages/edify-image">demo API</a> /
            <a href="https://www.youtube.com/watch?v=opiaV94tMJ4">video</a> /
            <a shape="rect" href="javascript:togglebib('edifyimage')" class="togglebib">bibtex</a>
            <pre xml:space="preserve">
@article{nvidia2024edifyimage,
    title     = {Edify Image: High-Quality Image Generation with Pixel Space Laplacian Diffusion Models},
    author    = {NVIDIA and Yuval Atzmon and Maciej Bala and Yogesh Balaji and Tiffany Cai and Yin Cui and Jiaojiao Fan and Yunhao Ge and Siddharth Gururani and Jacob Huffman and Ronald Isaac and Pooya Jannaty and Tero Karras and Grace Lam and J. P. Lewis and Aaron Licata and Yen-Chen Lin and Ming-Yu Liu and Qianli Ma and Arun Mallya and Ashlee Martino-Tarr and Doug Mendez and Seungjun Nah and Chris Pruett and Fitsum Reda and Jiaming Song and Ting-Chun Wang and Fangyin Wei and Xiaohui Zeng and Yu Zeng and Qinsheng Zhang},
    journal   = {arXiv preprint arXiv:2411.07126},
    year      = {2024},
    url       = {https://arxiv.org/abs/2411.07126}
}
            </pre>
          </div>
        </td>
        </td>
      </table>
    </div>
    <hr>

    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="25%" valign="top"><img src="fig/neurips2024.gif" alt="4d-rotor gaussian splatting" width="180"  style="border-style: none">
        <td width="75%" valign="top">
						<h4><h4><span class="h4">VCR-GauS: View Consistent Depth-Normal Regularizer for Gaussian Surface Reconstruction
								</span></h4>
				<h5>
                    <a href="https://hlinchen.github.io/hlchen/">Hanlin Chen</a>,
                    <strong>Fangyin Wei</strong>,
	  	<a href="https://chaneyddtt.github.io">Chen Li</a>,
	  	<a href="https://tianxinhuang.github.io/">Tianxin Huang</a>,
	  	<a href="https://scholar.google.com/citations?user=vv1uLeUAAAAJ&hl=en">Yunsong Wang</a>,
	  	<a href="https://www.comp.nus.edu.sg/~leegh/">Gim Hee Lee</a>
        </h5>

          <em>Conference on Neural Information Processing Systems (NeurIPS)</em>, 2024 &nbsp
          <div class="paper" id="neurips2024">
							<a href="https://arxiv.org/abs/2406.05774">paper</a> /
            <a href="https://hlinchen.github.io/projects/VCR-GauS/">webpage</a> /
            <a href="https://github.com/HLinChen/VCR-GauS">code</a> /
            <a shape="rect" href="javascript:togglebib('neurips2024')" class="togglebib">bibtex</a>
            <pre xml:space="preserve">
@inproceedings{chen:2024:vcrgaus,
   author = "Hanlin Chen and Fangyin Wei and Chen Li and Tianxing Huang and Yunsong Wang and Gim Hee Lee",
   title = "VCR-GauS: View Consistent Depth-Normal Regularizer for Gaussian Surface Reconstruction",
   booktitle = "Advances in Neural Information Processing Systems",
   year = "2024"
}
            </pre>
          </div>
        </td>
        </td>
      </table>
    </div>
    <hr>

    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="25%" valign="top"><img src="fig/siggraph2024-genusd.jpg" alt="GenUSD" width="180"  style="border-style: none">
        <td width="75%" valign="top">
						<h4><h4><span class="h4">GenUSD: 3D Scene Generation Made Easy
								</span></h4>
				<h5>
                    NVIDIA (<strong>Fangyin Wei</strong>: core contributor)
        </h5>

          <em></em>ACM SIGGRAPH Real-Time Live!, 2024 &nbsp
          <div class="paper" id="genusd">
							<a href="https://dl.acm.org/doi/pdf/10.1145/3641520.3665306">paper</a> /
            <a href="https://www.youtube.com/watch?v=Gm1B5DT8kE0&t=1752s">video (live demo)</a> /
            <a href="https://blogs.nvidia.com/blog/real-time-3d-generative-ai-research-siggraph-2024/">blog</a>
            <!--<a shape="rect" href="javascript:togglebib('edify3d')" class="togglebib">bibtex</a>-->
            <!--<pre xml:space="preserve">-->
            <!--</pre>-->
          </div>
        </td>
        </td>
      </table>
    </div>
    <hr>


    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="25%" valign="top"><img src="4drotorgs/4drotorgs.gif" alt="4d-rotor gaussian splatting" width="180"  style="border-style: none">
        <td width="75%" valign="top">
						<h4><h4><span class="h4">4D-Rotor Gaussian Splatting: Towards Efficient Novel-View Synthesis for Dynamic Scenes
								</span></h4>
				<h5>Yuanxing Duan*, <strong>Fangyin Wei*</strong>,
	  	<a href="https://daiqy.github.io">Qiyu Dai</a>,
	  	Yuhang He,
	  	<a href="https://www.cs.toronto.edu/~wenzheng/">Wenzheng Chen</a>,
	  	<a href="https://baoquanchen.info">Baoquan Chen</a>
        </h5>

          <em>Proc. SIGGRAPH</em>, 2024 &nbsp
          <div class="paper" id="siggraph2024">
							<a href="https://arxiv.org/abs/2402.03307">paper</a> /
            <a href="https://weify627.github.io/4drotorgs/">webpage</a> /
            <a href="https://github.com/weify627/4D-Rotor-Gaussians/tree/main">code</a> /
            <a shape="rect" href="javascript:togglebib('siggraph2024')" class="togglebib">bibtex</a>
            <pre xml:space="preserve">
@inproceedings{duan:2024:4drotorgs,
   author = "Yuanxing Duan and Fangyin Wei and Qiyu Dai and Yuhang He and Wenzheng Chen and Baoquan Chen",
   title = "4D-Rotor Gaussian Splatting: Towards Efficient Novel-View Synthesis for Dynamic Scenes",
   booktitle = "Proc. SIGGRAPH",
   year = "2024",
   month = July
}
            </pre>
          </div>
        </td>
        </td>
      </table>
    </div>
    <hr>

    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="25%" valign="top"><img src="clutter/img/teaser.gif" alt="clutter removal" width="180"  style="border-style: none">
        <td width="75%" valign="top">
						<h4><h4><span class="h4">Clutter Detection and Removal in 3D Scenes with View-Consistent Inpainting
								</span></h4>
				<h5><strong>Fangyin Wei</strong>,
	  	<a href="https://www.cs.princeton.edu/~funk/">Thomas Funkhouser</a>,
        <a href="https://www.cs.princeton.edu/~smr/">Szymon Rusinkiewicz</a>
        </h5>

          <em>International Conference on Computer Vision (ICCV)</em>, 2023 &nbsp
          <div class="paper" id="iccv2023b">
							<a href="https://arxiv.org/abs/2304.03763">paper (full)</a> /
            <a href="https://weify627.github.io/clutter/">webpage</a> /
            <a shape="rect" href="javascript:togglebib('iccv2023b')" class="togglebib">bibtex</a>
            <pre xml:space="preserve">
@inproceedings{Wei:2023:CDA,
   author = "Fangyin Wei and Thomas Funkhouser and Szymon Rusinkiewicz",
   title = "Clutter Detection and Removal in {3D} Scenes with View-Consistent Inpainting",
   booktitle = "International Conference on Computer Vision (ICCV)",
   year = "2023",
   month = oct
}
            </pre>
          </div>
        </td>
        </td>
      </table>
    </div>
    <hr>

    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="25%" valign="top"><img src="fig/iccv2023-uni-3d.png" alt="Uni-3D" width="180"  style="border-style: none">
        <td width="75%" valign="top">
						<h4><h4><span class="h4">Uni-3D: A Universal Model for Panoptic 3D Scene Reconstruction
								</span></h4>
                                <h5>
	  	<a href="https://xzhang.dev">Xiang Zhang*</a>,
	  	<a href="https://zeyuan-chen.com">Zeyuan Chen*</a>,
				<strong>Fangyin Wei</strong>,
        <a href="https://pages.ucsd.edu/~ztu/">Zhuowen Tu</a>
        </h5>

          <em>International Conference on Computer Vision (ICCV)</em>, 2023 &nbsp
          <div class="paper" id="iccv2023">
							<a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Uni-3D_A_Universal_Model_for_Panoptic_3D_Scene_Reconstruction_ICCV_2023_paper.pdf">paper</a> /
            <a href="https://github.com/mlpc-ucsd/Uni-3D">code</a> /
            <a shape="rect" href="javascript:togglebib('iccv2023')" class="togglebib">bibtex</a>
            <pre xml:space="preserve">
@InProceedings{Zhang_2023_ICCV,
    author    = {Zhang, Xiang and Chen, Zeyuan and Wei, Fangyin and Tu, Zhuowen},
    title     = {Uni-3D: A Universal Model for Panoptic 3D Scene Reconstruction},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    month     = {October},
    year      = {2023},
    pages     = {9256-9266}
}
            </pre>
          </div>
        </td>
        </td>
      </table>
    </div>
    <hr>
    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="25%" valign="top"><img src="nasam/img/real.gif" alt="articulated object" width="180"  style="border-style: none">
        <td width="75%" valign="top">
						<h4><h4><span class="h4">Self-supervised Neural Articulated Shape and Appearance Models
								</span></h4>
				<h5><strong>Fangyin Wei</strong>,
				<a href="https://scholar.google.com/citations?user=A3x7UAYAAAAJ&hl=en"> Rohan Chabra</a>,
				<a href="https://scholar.google.nl/citations?user=eUAgpwkAAAAJ&hl=en"> Lingni Ma</a>,
				<a href="https://christophlassner.de"> Christoph Lassner</a>,
				<a href="https://zollhoefer.com"> Michael Zollh√∂fer</a>,</br>
				<a href="https://www.cs.princeton.edu/~smr/"> Szymon Rusinkiewicz</a>,
				<a href="https://scholar.google.com/citations?user=h-CpQGgAAAAJ&hl=en"> Chris Sweeney</a>,
				<a href="https://scholar.google.com/citations?user=MhowvPkAAAAJ"> Richard Newcombe</a>,
				<a href="https://scholar.google.de/citations?user=cJKcPcIAAAAJ&hl=en"> Mira Slavcheva</a>
        </h5>

          <em>Computer Vision and Pattern Recognition (CVPR)</em>, 2022 &nbsp
          <div class="paper" id="cvpr2022">
            <a href="https://arxiv.org/abs/2205.08525">paper (full)</a> /
            <a href="https://weify627.github.io/nasam/">webpage</a> /
            <a shape="rect" href="javascript:togglebib('cvpr2022')" class="togglebib">bibtex</a>
            <pre xml:space="preserve">
@inproceedings{wei2022nasam,
    title = {Self-supervised Neural Articulated Shape and Appearance Models},
    author = {Fangyin Wei and Rohan Chabra and Lingni Ma and Christoph
              Lassner and Michael Zollhoefer and Szymon Rusinkiewicz and Chris
              Sweeney and Richard Newcombe and Mira Slavcheva},
    booktitle = {Proceedings IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    year={2022}
}
            </pre>
          </div>
        </td>
        </td>
      </table>
    </div>
    <hr>

    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="25%" valign="top"><img src="fig/3dv2020.png" alt="semantic edit" width="180"  style="border-style: none">
        <td width="75%" valign="top">
						<h4><h4><span class="h4">Learning to Infer Semantic Parameters for 3D Shape Editing
								</span></h4>
				<h5><strong>Fangyin Wei</strong>,
        <a href="https://esizikova.github.io">Elena Sizikova</a>,
		<a href="https://scholar.google.com/citations?hl=en&user=zc6Iy0IAAAAJ&view_op=list_works">Avneesh Sud</a>,
        <a href="https://www.cs.princeton.edu/~smr/">Szymon Rusinkiewicz</a>,
	  	<a href="https://www.cs.princeton.edu/~funk/">Thomas Funkhouser</a>
        </h5>

          <em>International Conference on 3D Vision (3DV)</em>, 2020 &nbsp
          <div class="paper" id="3dv2020">
            <a href="https://www.cs.princeton.edu/~fwei/projects/InferSemEdit/Learning_to_Infer_Semantic_Parameters_for_3D_Shape_Editing_3DV_128.pdf">paper</a> /
            <a href="https://www.cs.princeton.edu/~fwei/projects/InferSemEdit/Learning_to_Infer_Semantic_Parameters_for_3D_Shape_Editing_3DV_128_sup.pdf">supplement</a> /
            <a href="https://arxiv.org/abs/2011.04755">arXiv (full)</a> /
            <!--<a href="https:">webpage</a> /
            <a href="">code (coming out soon)</a> /-->
            <a shape="rect" href="javascript:togglebib('3dv2020')" class="togglebib">bibtex</a>
            <pre xml:space="preserve">
@inproceedings{Wei:2020:LTI,
   author = "Fangyin Wei and Elena Sizikova and Avneesh Sud and Szymon Rusinkiewicz
      and Thomas Funkhouser",
   title = "Learning to Infer Semantic Parameters for {3D} Shape Editing",
   booktitle = "International Conference on 3D Vision (3DV)",
   year = "2020",
   month = nov
}
            </pre>
          </div>
        </td>
        </td>
      </table>
    </div>
    <hr>

    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="25%" valign="top"><img src="fig/siggraphasia2020.png" alt="NLOS Imaging" width="180"  style="border-style: none">
        <td width="75%" valign="top">
	  	<h4><span class="h4">Learned Feature Embeddings for Non-Line-of-Sight Imaging and Recognition
        </span></h4>
				<h5>
        <a href="http://www.cs.toronto.edu/~wenzheng/">Wenzheng Chen*</a>, <strong>Fangyin Wei</strong>*,
		<a href="http://www.cs.toronto.edu/~kyros/">Kyros Kutulakos</a>,
        <a href="https://www.cs.princeton.edu/~smr/">Szymon Rusinkiewicz</a>,
	  	<a href="http://www.cs.princeton.edu/~fheide/">Felix Heide </a>
			</h5>

          <em>ACM Transactions on Graphics (Proc. SIGGRAPH Asia)</em>, 2020 &nbsp
          <div class="paper" id="siggraphasia2020">
            <a href="https://light.cs.princeton.edu/wp-content/uploads/2020/09/NLOS-LearnedFeatures-main.pdf">paper</a> /
            <a href="https://light.cs.princeton.edu/wp-content/uploads/2020/09/NLOS-LearnedFeatures-supplement.pdf">supplement</a> /
            <a href="https://light.cs.princeton.edu/publication/nlos-learnedfeatures/">webpage</a> /
            <a href="https://github.com/princeton-computational-imaging/NLOSFeatureEmbeddings">code</a> /
            <a shape="rect" href="javascript:togglebib('siggraphasia2020')" class="togglebib">bibtex</a>
            <pre xml:space="preserve">
@article{Chen:NLOS:2020,
title = {Learned Feature Embeddings for Non-Line-of-Sight Imaging and Recognition},
author = {Wenzheng Chen and Fangyin Wei and Kiriakos N. Kutulakos and Szymon Rusinkiewicz and Felix Heide},
year = {2020},
issue_date = {December 2020},
publisher = {Association for Computing Machinery},
volume = {39},
number = {6},
journal = {ACM Transactions on Graphics (Proc. SIGGRAPH Asia)},
}
            </pre>
          </div>
        </td>
        </td>
      </table>
    </div>
    <hr>

    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="25%" valign="top"><img src="fig/cvpr2020.png" alt="NLOS Detection and Tracking" width="180"  style="border-style: none">
        <td width="75%" valign="top">
	  	<h4><span class="h4">Seeing Around Street Corners: Non-Line-of-Sight Detection and Tracking In-the-Wild Using Doppler Radar</span></h4>
			<h5>Nicolas Scheiner*, Florian Kraus*, <strong>Fangyin Wei</strong>*, Buu Phan,
		<a href="http://www.cim.mcgill.ca/~fmannan/">Fahim Mannan</a>,
		Nils Appenrodt, Werner Ritter, J&#252rgen Dickmann, Klaus Dietmayer, Bernhard Sick,
	  	<a href="http://www.cs.princeton.edu/~fheide/">Felix Heide </a>
			</h5>

          <em>Computer Vision and Pattern Recognition (CVPR)</em>, 2020 &nbsp
          <div class="paper" id="cvpr2020">
            <a href="https://arxiv.org/abs/1912.06613">paper</a> /
            <a href="https://www.cs.princeton.edu/~fheide/DopplerNLOS/">webpage</a> /
            <a href="https://github.com/princeton-computational-imaging/doppler_nlos"> code</a> /
            <a shape="rect" href="javascript:togglebib('cvpr2020')" class="togglebib">bibtex</a>
            <pre xml:space="preserve">
@InProceedings{scheiner2019seeing,
author={Scheiner, Nicolas and Kraus, Florian and Wei, Fangyin and Phan, Buu and Mannan, Fahim and Appenrodt, Nils and Ritter, Werner and Dickmann, J{\"u}rgen and Dietmayer, Klaus and Sick, Bernhard and Heide, Felix},
title={Seeing Around Street Corners: Non-Line-of-Sight Detection and Tracking In-the-Wild Using Doppler Radar},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2020}
}
            </pre>
          </div>
        </td>
        </td>
      </table>
    </div>
    <hr>


		    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="25%" valign="top" halign="left"><img src="fig/nn2019.png" alt="RSA" width="180" height="100" style="border-style: none">
        <td width="75%" valign="top">
          <h4><span class="h4">ADA-Tucker: Compressing deep neural networks via adaptive dimension adjustment tucker decomposition</span></h4>
					<h5>    Zhisheng Zhong</a>,
		    <strong>Fangyin Wei</strong>,
		    <a href="http://www.cis.pku.edu.cn/faculty/vision/zlin/zlin.htm">Zhouchen Lin</a>,
            <a href="http://www.cis.pku.edu.cn/faculty/vision/zhangchao/zhangchao.htm">Chao Zhang</a>
</h5></center>
          <em>Neural Networks</em> 110: 104-115, 2019 &nbsp

          <div class="paper" id="nn2019" align="left">
            <a href="https://www.sciencedirect.com/science/article/pii/S0893608018303010">paper</a> /
            <a shape="rect" href="javascript:togglebib('nn2019')" class="togglebib">bibtex</a></span>
            <pre xml:space="preserve">
@article{DBLP:journals/nn/ZhongWLZ19,
  author    = {Zhisheng Zhong and
               Fangyin Wei and
               Zhouchen Lin and
               Chao Zhang},
  title     = {ADA-Tucker: Compressing deep neural networks via adaptive dimension
               adjustment tucker decomposition},
  journal   = {Neural Networks},
  volume    = {110},
  pages     = {104--115},
  year      = {2019},
  url       = {https://doi.org/10.1016/j.neunet.2018.10.016},
}
            </pre>
          </div>
        </td>
        </td>
      </table>
    </div>
	<hr>

    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="25%" valign="top"><img src="fig/eccv2018.png" alt="integral regression" width="180" height="70" style="border-style: none">
        <td width="75%" valign="top">
	  <h4><span class="h4">Integral Human Pose Regression</span></h4>
		<h5><a href="https://jimmysuen.github.io/"> Xiao Sun</a>,
	  <a href="https://github.com/leoxiaobin"> Bin Xiao</a>,
	  <strong>Fangyin Wei</strong>, <a href=""> Shuang Liang</a>,
	  <a href="https://scholar.google.com/citations?user=8qSLKUEAAAAJ&hl=en&oi=ao"> Yichen Wei</a>
		</h5>

          <em>European Conference of Computer Vision (ECCV)</em>, 2018 &nbsp
          <div class="paper" id="eccv2018">
            <a href="https://arxiv.org/abs/1711.08229">paper</a> /
            <a href="https://github.com/JimmySuen/integral-human-pose"> code</a> /
            <a shape="rect" href="javascript:togglebib('eccv2018')" class="togglebib">bibtex</a>
            <pre xml:space="preserve">
@InProceedings{sun2017integral,
  author    = {Xiao Sun and
               Bin Xiao and
	       Fangyin Wei and
               Shuang Liang and
               Yichen Wei},
  title     = {Integral Human Pose Regression},
  booktitle = {ECCV},
  year      = {2018}
  }
            </pre>
          </div>
        </td>
        </td>
      </table>
    </div>
    <hr>

    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="25%" valign="top"><img src="fig/cvpr2018.png" alt="D^2AE" width="180" height="120" style="border-style: none">
        <td width="75%" valign="top">
          <h4><span class="h4">Exploring Disentangled Feature Representation Beyond Face Identification</span></h4>
					<h5><a href="http://www.ee.cuhk.edu.hk/~yuliu/">Yu Liu</a>*,
		  <strong>Fangyin Wei</strong>*,
		    <a href="http://www.ee.cuhk.edu.hk/~jshao/">Jing Shao</a>*,
  <a href="http://www.ee.cuhk.edu.hk/~lsheng/">Lu Sheng</a>,
  <a href="http://www.cbsr.ia.ac.cn/users/jjyan/main.htm">Junjie Yan</a>,
  <a href="http://www.ee.cuhk.edu.hk/~xgwang/">Xiaogang Wang</a></h5></center>
          <em>Computer Vision and Pattern Recognition (CVPR)</em>, 2018 &nbsp

          <div class="paper" id="cvpr2018">
		  	<a href="https://arxiv.org/abs/1804.03487">paper</a>/
            <a href="http://liuyu.us/project/cvpr18_d2ae/">webpage</a> /
			<a href="http://liuyu.us/project/cvpr18_d2ae/fig/Poster_cvpr_D2AE_project_page.pdf">poster</a> /
            <a shape="rect" href="javascript:togglebib('cvpr2018')" class="togglebib">bibtex</a></span>
            <pre xml:space="preserve">
@InProceedings{liu2018exploring,
  title={Exploring Disentangled Feature Representation Beyond Face Identification},
  author={Liu, Yu and Wei, Fangyin and Shao, Jing and Sheng, Lu and Yan, Junjie and Wang, Xiaogang},
  booktitle={CVPR},
  year={2018}
}
            </pre>
          </div>
        </td>
        </td>
      </table>
    </div>
	<hr>


	    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="25%" valign="top" halign="left"><img src="fig/iccv2017.png" alt="RSA" width="180" height="120" style="border-style: none">
        <td width="75%" valign="top">
          <h4><span class="h4">Recurrent Scale Approximation for Object Detection in CNN</span></h4>
					<h5><a href="http://www.ee.cuhk.edu.hk/~yuliu/">Yu Liu</a>,
	      <a href="http://www.ee.cuhk.edu.hk/~yangli/">Hongyang Li </a>,
		   <a href="http://www.cbsr.ia.ac.cn/users/jjyan/main.htm">Junjie Yan</a>,
		    <strong>Fangyin Wei</strong>,
		    <a href="http://www.ee.cuhk.edu.hk/~xgwang/">Xiaogang Wang</a>,
            <a href="https://www.ie.cuhk.edu.hk/people/xotang.shtml">Xiaoou Tang</a>
</h5></center>
          <em>International Conference of Computer Vision (ICCV)</em>, 2017 &nbsp

          <div class="paper" id="iccv2017" align="left">
            <a href="https://arxiv.org/abs/1707.09531">paper</a> /
			<a href="https://github.com/sciencefans/RSA-for-object-detection">code</a> /
            <a shape="rect" href="javascript:togglebib('iccv2017')" class="togglebib">bibtex</a></span>
            <pre xml:space="preserve">
@InProceedings{liu2018rsa,
  title={Recurrent Scale Approximation for Object Detection in {CNN}},
  author={Yu Liu and
          Hongyang Li and
          Junjie Yan and
          Fangyin Wei and
          Xiaogang Wang and
          Xiaoou Tang},
  booktitle={ICCV},
  year={2017}
}
            </pre>
          </div>
        </td>
        </td>
      </table>
    </div>
	<hr>

  </div>
  <br>

  </div>
  <br>
  <div class="container">
    <h2>Professional Services</h2>
    <br>
        <ul align="left">
         <li><span> Conference Reviewer: CVPR (2025 outstanding reviewer), ICCV, ECCV, NeurIPS, ICML, ICLR, ICRA, 3DV, WACV, ISMAR
         <li><span> Journal Reviewer: SIGGRAPH, SIGGRAPH Asia
        </ul>
  </div>
  <br>

  <div class="container">
      <h2> Teaching </h2><br>
      <p align="left"> <b>Teaching Assistant </b></p>
      <p align="left"> Princeton University COS 526: Neural Rendering, Spring 2023</p>
      <p align="left"> Princeton University <a href="https://www.cs.princeton.edu/courses/archive/fall20/cos302/">COS 302: Mathematics for Numerical Computing and Machine Learning, Fall 2020</a></p>
      <p align="left"> Princeton University <a href="https://www.cs.princeton.edu/courses/archive/spring20/cos302/">COS 302: Mathematics for Numerical Computing and Machine Learning, Spring 2020</a></p>
      <p align="left"> Princeton University <a href="https://www.cs.princeton.edu/courses/archive/fall19/cos429/">COS 429: Computer Vision, Fall 2019</a></p>

  </div>
  <p style="text-align:right;">Web design stolen from <a href="https://jonbarron.info/">Jon Barron</a></p>


<script xml:space="preserve" language="JavaScript">
hideallbibs();
</script>


</body>
</html>
